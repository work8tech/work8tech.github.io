1:"$Sreact.fragment"
2:I[40136,["38","static/chunks/38-8e19ae4f5931341d.js","880","static/chunks/880-fc7b238551ed1847.js","978","static/chunks/978-8edb41050b0af9db.js","177","static/chunks/app/layout-aa3333012030f48c.js"],"MainLayout"]
3:I[87555,[],""]
4:I[31295,[],""]
5:I[52558,["38","static/chunks/38-8e19ae4f5931341d.js","880","static/chunks/880-fc7b238551ed1847.js","978","static/chunks/978-8edb41050b0af9db.js","177","static/chunks/app/layout-aa3333012030f48c.js"],"Toaster"]
6:I[45025,["38","static/chunks/38-8e19ae4f5931341d.js","974","static/chunks/app/page-841a8e39ce723421.js"],"Accordion"]
7:I[45025,["38","static/chunks/38-8e19ae4f5931341d.js","974","static/chunks/app/page-841a8e39ce723421.js"],"AccordionItem"]
8:I[45025,["38","static/chunks/38-8e19ae4f5931341d.js","974","static/chunks/app/page-841a8e39ce723421.js"],"AccordionTrigger"]
9:I[45025,["38","static/chunks/38-8e19ae4f5931341d.js","974","static/chunks/app/page-841a8e39ce723421.js"],"AccordionContent"]
a:I[59665,[],"MetadataBoundary"]
c:I[59665,[],"OutletBoundary"]
f:I[74911,[],"AsyncMetadataOutlet"]
11:I[59665,[],"ViewportBoundary"]
13:I[26614,[],""]
:HL["/Statistics/_next/static/css/1f1d5ce6bc25079e.css","style"]
0:{"P":null,"b":"2HwQgLyCV8zxf-kgFw8vJ","p":"/Statistics","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/Statistics/_next/static/css/1f1d5ce6bc25079e.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"href":"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap","rel":"stylesheet"}]]}],["$","body",null,{"className":"font-body antialiased","children":[["$","$L2",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L5",null,{}]]}]]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"container mx-auto p-4 md:p-8","children":[["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-4xl font-bold tracking-tight text-foreground font-headline","children":"Statistics & Probability Theory Guide"}],["$","p",null,{"className":"mt-2 text-lg text-muted-foreground","children":"Your comprehensive guide to an a to understanding the core concepts."}]]}],["$","div",null,{"ref":"$undefined","className":"rounded-lg border bg-card text-card-foreground shadow-sm w-full","children":[["$","div",null,{"ref":"$undefined","className":"flex flex-col space-y-1.5 p-6","children":["$","div",null,{"ref":"$undefined","className":"text-2xl font-semibold leading-none tracking-tight","children":"Core Concepts"}]}],["$","div",null,{"ref":"$undefined","className":"p-6 pt-0","children":["$","$L6",null,{"type":"multiple","className":"w-full space-y-2","children":[["$","$L7",null,{"value":"item-1","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Foundations of Probability"}],["$","$L9",null,{"className":"text-base leading-relaxed space-y-4","children":[["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Sample Space & Events:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Sample Space (S):"}]," The set of all possible outcomes of a random experiment."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Event (A):"}]," A subset of the sample space; a collection of one or more outcomes."]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Probability Axioms:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Non-negativity:"}]," For any event A, P(A) ≥ 0."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Total Probability:"}]," The probability of the entire sample space S is 1, i.e., P(S) = 1."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Additivity:"}]," For any sequence of mutually exclusive events A₁, A₂, ..., P(A₁ ∪ A₂ ∪ ...) = Σ P(Aᵢ)."]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Types of Events:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Mutually Exclusive Events:"}]," Events that cannot occur at the same time. P(A ∩ B) = 0."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Independent Events:"}]," The occurrence of one event does not affect the probability of another. P(A ∩ B) = P(A) * P(B)."]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Types of Probability:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Joint Probability P(A ∩ B):"}]," The probability of both event A and event B occurring."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Marginal Probability P(A):"}]," The probability of a single event occurring, irrespective of other events."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Conditional Probability P(A|B):"}]," The probability of event A occurring given that event B has already occurred. Formula: P(A|B) = P(A ∩ B) / P(B)."]}]]}]]}]]}]]}],["$","$L7",null,{"value":"item-2","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Counting: Permutations & Combinations"}],["$","$L9",null,{"className":"text-base leading-relaxed space-y-4","children":[["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Permutation (Order Matters):"}],["$","p",null,{"children":"The number of ways to arrange 'k' objects from a set of 'n' distinct objects."}],["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"P(n, k) = n! / (n - k)!"}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Combination (Order Doesn't Matter):"}],["$","p",null,{"children":"The number of ways to choose 'k' objects from a set of 'n' distinct objects."}],["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"C(n, k) = n! / (k! * (n - k)!)"}]]}]]}]]}],["$","$L7",null,{"value":"item-3","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Descriptive Statistics"}],["$","$L9",null,{"className":"text-base leading-relaxed space-y-4","children":[["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Measures of Central Tendency:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Mean (μ or E[X]):"}]," The average value. Population mean μ = (Σxᵢ) / N. Sample mean x̄ = (Σxᵢ) / n."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Median:"}]," The middle value of an ordered dataset."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Mode:"}]," The most frequent value in a dataset."]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Measures of Dispersion & Relationship:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Variance (σ² or Var(X)):"}]," Average of the squared differences from the Mean. σ² = Σ(xᵢ - μ)² / N."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Standard Deviation (σ):"}]," Square root of variance, measuring data spread. σ = √σ²."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Covariance (Cov(X,Y)):"}]," Measures how two variables change together. Cov(X,Y) = E[(X - E[X])(Y - E[Y])]."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Correlation (ρ):"}]," A standardized measure of the linear relationship between two variables, from -1 to +1. ρ = Cov(X,Y) / (σₓσᵧ)."]}]]}]]}]]}]]}],["$","$L7",null,{"value":"item-4","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Bayes' Theorem"}],["$","$L9",null,{"className":"text-base leading-relaxed","children":[["$","p",null,{"children":"Bayes' Theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event."}],["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"P(A|B) = [P(B|A) * P(A)] / P(B)"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"P(A|B) (Posterior):"}]," Probability of hypothesis A given evidence B."]}],["$","li",null,{"children":[["$","strong",null,{"children":"P(B|A) (Likelihood):"}]," Probability of evidence B given hypothesis A is true."]}],["$","li",null,{"children":[["$","strong",null,{"children":"P(A) (Prior):"}]," The initial probability of hypothesis A."]}],["$","li",null,{"children":[["$","strong",null,{"children":"P(B) (Marginal):"}]," The probability of the evidence."]}]]}]]}]]}],["$","$L7",null,{"value":"item-5","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Random Variables"}],["$","$L9",null,{"className":"text-base leading-relaxed space-y-4","children":[["$","div",null,{"children":[["$","p",null,{"children":"A random variable is a variable whose value is a numerical outcome of a random phenomenon."}],["$","h4",null,{"className":"font-semibold text-md mt-2","children":"Discrete Random Variables:"}],["$","p",null,{"children":["Have a countable number of possible values. Described by a ",["$","strong",null,{"children":"Probability Mass Function (PMF)"}],", P(X=x), which gives the probability of the variable taking a specific value x."]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Continuous Random Variables:"}],["$","p",null,{"children":["Can take any value within a given range. Described by a ",["$","strong",null,{"children":"Probability Density Function (PDF)"}],", f(x), where the area under the curve between two points gives the probability of the variable falling in that interval. P(a ≤ X ≤ b) = ∫ₐᵇ f(x)dx."]}],["$","p",null,{"className":"mt-2","children":["A ",["$","strong",null,{"children":"Conditional PDF"}]," f(x|Y=y) gives the probability density of X given that Y has occurred."]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Key Concepts:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Cumulative Distribution Function (CDF):"}]," F(x) = P(X ≤ x). For any random variable, it gives the probability of the variable being less than or equal to x."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Conditional Expectation (E[X|Y=y]):"}]," The expected value of X given that Y has occurred."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Conditional Variance (Var(X|Y=y]):"}]," The variance of X given that Y has occurred."]}]]}]]}]]}]]}],["$","$L7",null,{"value":"item-6","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Common Probability Distributions"}],["$","$L9",null,{"className":"text-base leading-relaxed space-y-4","children":[["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Discrete Distributions:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Bernoulli:"}]," Describes a single trial with two outcomes (e.g., success/failure). Parameter: p (probability of success).",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PMF: P(X=1) = p, P(X=0) = 1-p"}],["$","li",null,{"children":"Mean (μ): p"}],["$","li",null,{"children":"Variance (σ²): p(1-p)"}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Binomial:"}]," Describes the number of successes in 'n' independent Bernoulli trials. Parameters: n (number of trials), p (probability of success).",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PMF: P(X=k) = C(n,k) * pᵏ * (1-p)ⁿ⁻ᵏ"}],["$","li",null,{"children":"Mean (μ): np"}],["$","li",null,{"children":"Variance (σ²): np(1-p)"}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Poisson:"}]," Describes the number of events occurring in a fixed interval of time or space, given a known average rate. Parameter: λ (lambda, average rate of events).",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PMF: P(X=k) = (λᵏ * e⁻ˡ) / k!"}],["$","li",null,{"children":"Mean (μ): λ"}],["$","li",null,{"children":"Variance (σ²): λ"}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Uniform (Discrete):"}]," Describes a situation where all 'n' outcomes are equally likely.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PMF: P(X=x) = 1/n"}],["$","li",null,{"children":"Mean (μ): (a+b)/2, for outcomes from a to b."}],["$","li",null,{"children":"Variance (σ²): ((b-a+1)²-1)/12"}]]}]]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Continuous Distributions:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Uniform (Continuous):"}]," All outcomes in a range [a,b] are equally likely.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PDF: f(x) = 1/(b-a) for a ≤ x ≤ b"}],["$","li",null,{"children":"Mean (μ): (a+b)/2"}],["$","li",null,{"children":"Variance (σ²): (b-a)²/12"}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Exponential:"}]," Time between events in a Poisson process. Parameter: λ (rate).",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PDF: f(x) = λe⁻ˡˣ for x ≥ 0"}],["$","li",null,{"children":"Mean (μ): 1/λ"}],["$","li",null,{"children":"Variance (σ²): 1/λ²"}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Normal (Gaussian):"}]," The \"bell curve,\" central to statistics due to the Central Limit Theorem. Parameters: μ (mean), σ (standard deviation).",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"PDF: A complex formula resulting in the bell shape, symmetric around the mean."}],["$","li",null,{"children":"Mean (μ): μ"}],["$","li",null,{"children":"Variance (σ²): σ²"}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Standard Normal Distribution (Z-distribution):"}]," A special case of the normal distribution where the mean (μ) is 0 and the standard deviation (σ) is 1. It is the distribution that results from standardizing any normal random variable.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Standardization (Z-score):"}]," The process of converting a value (x) from a normal distribution to a z-score. The z-score measures how many standard deviations an element is from the mean."]}],["$","li",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"z = (x - μ) / σ"}],["$","li",null,{"children":"This conversion is extremely useful because it allows us to compare values from different normal distributions and to use a single standard normal table (Z-table) to find probabilities for any normally distributed variable."}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"t-Distribution:"}]," A family of distributions that, like the normal distribution, is symmetric and bell-shaped, but has heavier tails.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":"It is primarily used for inference when the sample size is small (typically n < 30) and the population standard deviation is unknown. The \"heavier tails\" account for the extra uncertainty introduced by estimating the population standard deviation from the sample."}],["$","li",null,{"children":[["$","strong",null,{"children":"Parameter (Degrees of Freedom, df):"}]," The shape of the t-distribution is determined by its degrees of freedom, which are related to the sample size (often df = n-1)."]}],["$","li",null,{"children":"As the degrees of freedom increase (i.e., as the sample size gets larger), the t-distribution converges to the standard normal distribution. For df > 30, it is nearly identical to the normal distribution."}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Chi-Squared (χ²):"}]," Typically right-skewed, it's the distribution of a sum of squared standard normal deviates. It's defined by one parameter.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Parameter (Degrees of Freedom, df):"}]," The shape, center, and spread of the χ² distribution are determined by its degrees of freedom. The df represents the number of independent pieces of information that go into the calculation of the test statistic. The formula for df depends on the specific test being used.",["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"For a Goodness-of-Fit Test:"}]," The degrees of freedom are the number of categories minus 1.",["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"df = k - 1"}],["$","p",null,{"className":"text-xs","children":"Where 'k' is the number of categories or groups. Example: If you are testing if a die is fair by rolling it and checking the outcomes for 6 categories (1, 2, 3, 4, 5, 6), your df would be 6 - 1 = 5."}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"For a Test of Independence:"}]," The degrees of freedom are calculated based on the contingency table's dimensions.",["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"df = (rows - 1) * (columns - 1)"}],["$","p",null,{"className":"text-xs","children":"Where 'rows' is the number of categories for the first variable and 'columns' is the number of categories for the second. Example: If you're testing the relationship between smoking status (smoker, non-smoker) and education level (high school, college, graduate), your contingency table has 2 rows and 3 columns, so df = (2 - 1) * (3 - 1) = 2."}]]}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Use Cases:"}]," It is critical for ",["$","strong",null,{"children":"goodness-of-fit tests"}]," (checking if sample data comes from a specific distribution) and ",["$","strong",null,{"children":"tests of independence"}]," (checking if two categorical variables are related)."]}]]}]]}]]}]]}]]}]]}],["$","$L7",null,{"value":"item-7","children":[["$","$L8",null,{"className":"text-lg font-semibold","children":"Inferential Statistics & Hypothesis Testing"}],["$","$L9",null,{"className":"text-base leading-relaxed space-y-4","children":[["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Central Limit Theorem (CLT):"}],["$","p",null,{"children":"The CLT is a cornerstone of statistics. It states that for a large enough sample size (typically n ≥ 30), the sampling distribution of the sample mean (x̄) will be approximately normally distributed, regardless of the shape of the original population's distribution. This allows us to use normal distribution theory for making inferences about population means."}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Confidence Intervals:"}],["$","p",null,{"children":"A confidence interval provides a range of values, derived from sample data, that is likely to contain an unknown population parameter with a certain level of confidence."}],["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"Interval = Point Estimate ± (Critical Value * Standard Error)"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Point Estimate:"}]," A single value used to estimate the population parameter (e.g., the sample mean x̄)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Critical Value:"}]," A value from a distribution (like z or t) determined by the chosen confidence level (e.g., 1.96 for 95% confidence)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Standard Error:"}]," The standard deviation of the sampling distribution of the statistic (e.g., σ/√n for the mean)."]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"The Process of Hypothesis Testing:"}],["$","p",null,{"children":"This is a formal procedure for investigating our ideas about the world using statistics. It involves these steps:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"State the Hypotheses:"}]," Formulate a null hypothesis (H₀), which represents the status quo (e.g., \"no effect\"), and an alternative hypothesis (H₁ or Hₐ), which is what you want to prove."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Set the Significance Level (α):"}]," This is the probability of rejecting the null hypothesis when it is actually true (a Type I error). Common levels are 0.05, 0.01, and 0.10."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Calculate the Test Statistic:"}]," Compute a value from the sample data (e.g., a z-score or t-score) that measures how far your sample result is from the null hypothesis."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Determine the p-value:"}]," The p-value is the probability of observing a test statistic as extreme as, or more extreme than, the one calculated from your sample, assuming the null hypothesis is true."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Make a Decision:"}]," If the p-value is less than or equal to your significance level (p ≤ α), you reject the null hypothesis in favor of the alternative. Otherwise, you fail to reject the null hypothesis."]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-md","children":"Common Hypothesis Tests:"}],["$","ul",null,{"className":"list-disc pl-5 mt-2 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Z-Test:"}]," Used to test a hypothesis about a population mean when the population standard deviation (σ) is known and the sample size is large (typically n ≥ 30). Because σ is known, it uses the standard normal distribution.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":["$","strong",null,{"children":"Test Statistic Formula:"}]}],["$","li",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"z = (x̄ - μ₀) / (σ / √n)"}],["$","li",null,{"children":"Where x̄ is the sample mean, μ₀ is the hypothesized population mean, σ is the population standard deviation, and n is the sample size."}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"T-Test:"}]," Used when the population standard deviation (σ) is unknown and must be estimated from the sample. It relies on the t-distribution.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":[["$","strong",null,{"children":"One-Sample t-test:"}]," Compares the mean of a single sample to a known or hypothesized value.",["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"t = (x̄ - μ₀) / (s / √n)"}],["$","p",null,{"className":"text-xs","children":"Where s is the sample standard deviation and df = n-1."}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Independent Samples t-test:"}]," Compares the means of two separate, unrelated groups to determine if there is a significant difference between them.",["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"t = (x̄₁ - x̄₂) / (sₚ * √((1/n₁) + (1/n₂)))"}],["$","p",null,{"className":"text-xs","children":"Where sₚ is the pooled standard deviation and df = n₁ + n₂ - 2."}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Paired Samples t-test:"}]," Compares the means of two related groups (e.g., the same subjects before and after a treatment) to see if there is a significant change.",["$","p",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"t = d̄ / (sₔ / √n)"}],["$","p",null,{"className":"text-xs","children":"Where d̄ is the mean of the differences, sₔ is the standard deviation of the differences, and df = n-1."}]]}]]}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Chi-Squared (χ²) Test:"}]," Used for analyzing categorical data by comparing observed frequencies to expected frequencies. The test statistic measures the discrepancy between what is observed and what would be expected under the null hypothesis.",["$","ul",null,{"className":"list-circle pl-5 mt-1","children":[["$","li",null,{"children":["$","strong",null,{"children":"Test Statistic Formula:"}]}],["$","li",null,{"className":"font-mono bg-muted p-2 rounded-md my-2 text-sm","children":"χ² = Σ [ (Observed - Expected)² / Expected ]"}],["$","li",null,{"children":[["$","strong",null,{"children":"Goodness-of-Fit Test:"}]," Determines if a single categorical variable's frequency distribution matches a specific, hypothesized distribution.",["$","p",null,{"className":"text-sm mt-1","children":"Example: Testing if a six-sided die is fair by comparing the observed frequencies of rolls (e.g., 10 ones, 12 twos, etc.) to the expected frequency (e.g., 1/6 for each outcome)."}]]}],["$","li",null,{"children":[["$","strong",null,{"children":"Test of Independence:"}]," Determines if there is a significant association between two categorical variables. The test compares the observed frequencies in a contingency table to the frequencies that would be expected if the variables were independent.",["$","p",null,{"className":"text-sm mt-1","children":"Example: Testing whether there is a relationship between a person's favorite ice cream flavor (e.g., chocolate, vanilla, strawberry) and their gender (e.g., male, female)."}]]}]]}]]}]]}]]}]]}]]}]]}]}]]}]]}],["$","$La",null,{"children":"$Lb"}],null,["$","$Lc",null,{"children":["$Ld","$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","qUwKdrVb4DV8QPIs34Hnr",{"children":[["$","$L11",null,{"children":"$L12"}],null]}],null]}],false]],"m":"$undefined","G":["$13","$undefined"],"s":false,"S":true}
14:"$Sreact.suspense"
15:I[74911,[],"AsyncMetadata"]
b:["$","$14",null,{"fallback":null,"children":["$","$L15",null,{"promise":"$@16"}]}]
e:null
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
d:null
16:{"metadata":[["$","title","0",{"children":"StatWise"}],["$","meta","1",{"name":"description","content":"An interactive guide to probability and statistics."}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}]],"error":null,"digest":"$undefined"}
10:{"metadata":"$16:metadata","error":null,"digest":"$undefined"}
